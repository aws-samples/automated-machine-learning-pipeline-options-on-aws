{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement ML pipeline Using the AWS Glue Workflow\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Create Resources](#Create-Resources)\n",
    "1. [Build a Machine Learning Workflow](#Build-a-Machine-Learning-Workflow)\n",
    "1. [Run the Workflow](#Run-the-Workflow)\n",
    "1. [Clean Up](#Clean-Up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Introduction\"></a>\n",
    "## Introduction\n",
    "\n",
    "This notebook describes how to use Glue Workflow with PySpark scripts to create a machine learning pipeline across data preparation, model training, model evaluation and model register. The defintion of workflow as beflow:\n",
    "\n",
    "<div align=\"center\"><img width=300 src=\"images/glue_ml_workflow.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# !{sys.executable} -m pip install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "sys.path.insert( 0, os.path.abspath(\"../common\") )\n",
    "import setup_iam_roles\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "id = uuid.uuid4().hex\n",
    "\n",
    "# SageMaker Execution Role\n",
    "sagemaker_execution_role = sagemaker.get_execution_role()\n",
    "\n",
    "# Create a unique name for the AWS Glue job to be created. If you change the\n",
    "# default name, you may need to change the Step Functions execution role.\n",
    "glue_job_prefix = \"customer-churn-etl\"\n",
    "glue_job_name = f\"{glue_job_prefix}-{id}\"\n",
    "\n",
    "# Create a unique name for the AWS Lambda function to be created. If you change\n",
    "# the default name, you may need to change the Step Functions execution role.\n",
    "query_function_prefix = \"query-evaluation-result\"\n",
    "query_function_name = f\"{query_function_prefix}-{id}\"\n",
    "\n",
    "prefix = 'sagemaker/DEMO-xgboost-customer-churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create fine-grained IAM roles for the Lambda, Glue, and Step Functions resources. The IAM roles grant the services permissions within your AWS environment.\n",
    "\n",
    "### Add permissions to your notebook role in IAM\n",
    "\n",
    "The IAM role assumed by your notebook requires permission to create and run workflows in AWS Step Functions. If this notebook is running on a SageMaker notebook instance, do the following to provide IAM permissions to the notebook:\n",
    "\n",
    "1. Open the Amazon [SageMaker console](https://console.aws.amazon.com/sagemaker/). \n",
    "2. Select **Notebook instances** and choose the name of your notebook instance.\n",
    "3. Under **Permissions and encryption** select the role ARN to view the role on the IAM console.\n",
    "4. Copy and save the IAM role ARN for later use. \n",
    "5. Choose **Attach policies** and search for `AWSGlueConsoleSageMakerNotebookFullAccess`.\n",
    "6. Select the check box next to `AWSGlueConsoleSageMakerNotebookFullAccess` and choose **Attach policy**.\n",
    "\n",
    "We also need to provide permissions that allow the notebook instance the ability to create an AWS Lambda function and AWS Glue job. We will edit the managed policy attached to our role directly to encorporate these specific permissions:\n",
    "\n",
    "1. Under **Permisions policies** expand the AmazonSageMaker-ExecutionPolicy-******** policy and choose **Edit policy**.\n",
    "2. Select **Add additional permissions**. Choose **IAM**  for Service and **PassRole** for Actions.\n",
    "3. Under Resources, choose **Specific**. Select **Add ARN** and enter `query_training_status-role` for **Role name with path*** and choose **Add**. You will create this role later on in this notebook.\n",
    "4. Select **Add additional permissions** a second time. Choose **Lambda** for Service, **Write** for Access level, and **All resources** for Resources.\n",
    "5. Select **Add additional permissions** a final time. Choose **Glue** for Service, **Write** for Access level, and **All resources** for Resources.\n",
    "6. Choose **Review policy** and then **Save changes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an IAM role for Glue Job\n",
    "* Providing access on the S3 bucket\n",
    "* Executing SageMaker training job and model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::822507008821:role/AWS-Glue-S3-SageMaker-Access'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_role_name = \"AWS-Glue-S3-SageMaker-Access\"\n",
    "glue_role_arn = setup_iam_roles.create_glue_role(glue_role_name, bucket)\n",
    "glue_role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Dataset\n",
    "This notebook uses the XGBoost algorithm to automate the classification of unhappy customers for telecommunication service providers. The goal is to identify customers who may cancel their service soon so that you can entice them to stay. This is known as customer churn prediction.\n",
    "\n",
    "The dataset we use is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix = \"train\"\n",
    "val_prefix = \"validation\"\n",
    "test_prefix = \"test\"\n",
    "\n",
    "raw_data = f\"s3://{bucket}/{prefix}/input\"\n",
    "processed_data = f\"s3://{bucket}/{prefix}/processed\"\n",
    "\n",
    "train_data = f\"{processed_data}/{train_prefix}/\"\n",
    "validation_data = f\"{processed_data}/{val_prefix}/\"\n",
    "test_data = f\"{processed_data}/{test_prefix}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to `S3 Bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-822507008821/sagemaker/DEMO-xgboost-customer-churn/input/churn_processed.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3Uploader.upload(\n",
    "    local_path=\"../data/churn_processed.csv\",\n",
    "    desired_s3_uri=f\"{raw_data}\",\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Machine Learning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Glue Workflow as the orchestration engine, Glue Job for the data preprocessing and model training/deployment as the steps\n",
    "\n",
    "* [**Glue Workflow**](https://docs.aws.amazon.com/glue/latest/dg/workflows_overview.html) - Orchestration engine for ML workflow.\n",
    "* [**Glue Job**](https://docs.aws.amazon.com/glue/latest/dg/author-job.html) - Business logic for ETL or python shell.\n",
    "* [**Glue Trigger**](https://docs.aws.amazon.com/glue/latest/dg/trigger-job.html) - Triggers Glue Job as steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AWS Glue Workflow\n",
    "\n",
    "#### Create Glue Workflow Object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_client = boto3.client(\"glue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_workflow_name = f\"CustomerChurnMLWorkflow-{id}\"\n",
    "response = glue_client.create_workflow(\n",
    "    Name=glue_workflow_name,\n",
    "    Description='AWS Glue workflow to process data and create training jobs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Glue Jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Job\n",
    "data_processing_script_path = S3Uploader.upload(\n",
    "    local_path=\"../common/glue_preprocessing.py\",\n",
    "    desired_s3_uri=f\"s3://{bucket}/{prefix}/glue/scripts\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "data_processing_job_name = \"DataProcessingJob\"\n",
    "response = glue_client.create_job(\n",
    "    Name=data_processing_job_name,\n",
    "    Description='Preparing data for SageMaker training',\n",
    "    Role=glue_role_arn,\n",
    "    ExecutionProperty={\n",
    "        'MaxConcurrentRuns': 2\n",
    "    },\n",
    "    Command={\n",
    "        'Name': 'glueetl',\n",
    "        'ScriptLocation': data_processing_script_path,\n",
    "    },\n",
    "    DefaultArguments={\n",
    "        \"--job-bookmark-option\": \"job-bookmark-enable\",\n",
    "        \"--enable-metrics\": \"\",\n",
    "        \"--additional-python-modules\": \"pyarrow==2,awswrangler==2.9.0,fsspec==0.7.4\"\n",
    "    },\n",
    "    MaxRetries=0,\n",
    "    Timeout=60,\n",
    "    MaxCapacity=10.0,\n",
    "    GlueVersion='2.0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training & Deployment Job\n",
    "model_training_deployment_script_path = S3Uploader.upload(\n",
    "    local_path=\"./code/model_training_deployment.py\",\n",
    "    desired_s3_uri=f\"s3://{bucket}/{prefix}/glue/scripts\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "model_training_deployment_job_name = \"ModelTrainingDeploymentJob\"\n",
    "response = glue_client.create_job(\n",
    "    Name=model_training_deployment_job_name,\n",
    "    Description='Model training and deployment',\n",
    "    Role=glue_role_arn,\n",
    "    ExecutionProperty={\n",
    "        'MaxConcurrentRuns': 2\n",
    "    },\n",
    "    Command={\n",
    "        'Name': 'pythonshell',\n",
    "        'ScriptLocation': model_training_deployment_script_path,\n",
    "        'PythonVersion': '3'\n",
    "    },\n",
    "    DefaultArguments={\n",
    "        \"--job-bookmark-option\": \"job-bookmark-enable\",\n",
    "        \"--enable-metrics\": \"\"\n",
    "    },\n",
    "    MaxRetries=0,\n",
    "    Timeout=60,\n",
    "    MaxCapacity=1,\n",
    "    GlueVersion='1.0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_output_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-063c21e6355d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     Arguments={\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'--train_input_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'--model_output_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_output_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;34m'--algorithm_image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'--role_arn'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msagemaker_execution_role\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_output_path' is not defined"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "response = glue_client.start_job_run(\n",
    "    JobName=model_training_deployment_job_name,\n",
    "    Arguments={\n",
    "        '--train_input_path': processed_data,\n",
    "        '--model_output_path': model_output_path,\n",
    "        '--algorithm_image': image_uri,\n",
    "        '--role_arn': sagemaker_execution_role,\n",
    "    },\n",
    "    MaxCapacity=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Glue Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue_client.create_trigger(\n",
    "    Name='TriggerDataProcessingJob',\n",
    "    Description='Triggering Data Processing Job',\n",
    "    Type='ON_DEMAND',\n",
    "    WorkflowName=glue_workflow_name,\n",
    "    Actions=[\n",
    "        {\n",
    "            'JobName': data_processing_job_name,\n",
    "            'Arguments': {\n",
    "                '--INPUT_DIR': raw_data,\n",
    "                '--PROCESSED_DIR': processed_data\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "processed_data, sagemaker_execution_role, image_uri, model_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue_client.create_trigger(\n",
    "    Name='TriggerModelTrainingDeploymentJob',\n",
    "    Description='Triggering Model Training Deployment Job',\n",
    "    WorkflowName=glue_workflow_name,\n",
    "    Type='CONDITIONAL',\n",
    "    StartOnCreation=True,\n",
    "    Predicate={\n",
    "        'Conditions': [\n",
    "            {\n",
    "                'LogicalOperator': 'EQUALS',\n",
    "                'JobName': data_processing_job_name,\n",
    "                'State': 'SUCCEEDED'\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    Actions=[\n",
    "        {\n",
    "            'JobName': model_training_deployment_job_name,\n",
    "            'Arguments': {\n",
    "                '--train_input_path': processed_data,\n",
    "                '--model_output_path': model_output_path,\n",
    "                '--algorithm_image': image_uri,\n",
    "                '--role_arn': sagemaker_execution_role,\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Workflow Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "Create your workflow using the workflow definition above, and render the graph with [render_graph](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.render_graph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue_client.start_workflow_run(\n",
    "    Name=glue_workflow_name,\n",
    "#     RunProperties={\n",
    "#         'string': 'string'\n",
    "#     }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "When you are done, make sure to clean up your AWS account by deleting resources you won't be reusing. Uncomment the code below and run the cell to delete the Glue job, Lambda function, and Step Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deletion\n",
    "response = glue_client.delete_workflow(\n",
    "    Name=glue_workflow_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
